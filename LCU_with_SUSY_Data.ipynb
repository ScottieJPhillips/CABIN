{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60d69e8c-4fa5-4daf-a914-8c7e931ac330",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import torch\n",
    "import torch.nn\n",
    "import torch.optim\n",
    "import torch.utils.data\n",
    "import h5py\n",
    "from os.path import exists\n",
    "import time\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "\n",
    "\n",
    "# Importing LearningCutsUtils\n",
    "from LearningCutsUtils import OneToOneLinear, EfficiencyScanNetwork\n",
    "from LearningCutsUtils import loss_fn, effic_loss_fn, lossvars\n",
    "import LearningCutsUtils.Utils as LCU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "821a64eb-0c3c-435e-8663-45077950b7d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_sig_data=None\n",
    "y_sig_data=None\n",
    "\n",
    "x_bkg_data=None\n",
    "y_bkg_data=None\n",
    "\n",
    "num_sig_events=0\n",
    "num_bkg_events=0\n",
    "\n",
    "allbranches=(\n",
    "    'lep1Flavor','lep1Charge','lep1Pt','lep1Eta','lep1Phi','lep1MT_Met','lep1Signal','mt_lep1','lep1_DPhiMet',\n",
    "    'lep2Flavor','lep2Charge','lep2Pt','lep2Eta','lep2Phi','lep2MT_Met','lep2Signal','mt_lep2','lep2_DPhiMet',\n",
    "    'Rll','Ptll',\n",
    "    'nJet30','nBJet30',\n",
    "    'jet0Pt','jet0Eta','jet0Phi','jet0Btagged',\n",
    "    'jet1Pt','jet1Eta','jet1Phi','jet1Btagged',\n",
    "    'jet2Pt','jet2Eta','jet2Phi','jet2Btagged',\n",
    "    'jet3Pt','jet3Eta','jet3Phi','jet3Btagged',\n",
    "    'jet4Pt','jet4Eta','jet4Phi','jet4Btagged',\n",
    "    'met_Et','met_Phi',\n",
    "    'METOverHT','METOverHTLep',\n",
    "    'minDPhiAllJetsMet',\n",
    "    'MTauTau',\n",
    "    'mt2leplsp_100')\n",
    "\n",
    "branches=(\n",
    "    'lep1MT_Met',\n",
    "    'lep2MT_Met',\n",
    "    'met_Et',\n",
    "    'Rll') \n",
    "\n",
    "\n",
    "# open signal\n",
    "mass=200\n",
    "split=30\n",
    "filepath='/data/mhance/SUSY/Compressed/'\n",
    "filebase='SusySkimSlep_v0.2_SlepSignals__'\n",
    "filename='MGPy8EG_A14N23LO_SlepSlep_dir_2L2MET75_%dp0_%dp0_NoSys' % (mass,mass-split)\n",
    "filesuff='.hf5'\n",
    "fullname=filepath+filebase+filename+filesuff\n",
    "with h5py.File(fullname,'r') as hdf5file:\n",
    "    print(fullname)\n",
    "    data=hdf5file[list(hdf5file.keys())[0]]\n",
    "    num_sig_events=len(data[\"nJet30\"])\n",
    "    x_sig_data=data[branches]\n",
    "    y_sig_data=np.ones(num_sig_events)\n",
    "        \n",
    "print(\"Extracted %7d signal events\" % num_sig_events)\n",
    "\n",
    "fullname=filepath+\"SusySkimSlep_v0.2_diboson2L__diboson2L_NoSys\"+filesuff\n",
    "num_events=0\n",
    "with h5py.File(fullname,'r') as hdf5file:\n",
    "    print(fullname)\n",
    "    data=hdf5file[list(hdf5file.keys())[0]]\n",
    "    num_bkg_events=len(data[\"nJet30\"])\n",
    "    x_bkg_data=data[branches]\n",
    "    y_bkg_data=np.zeros(num_bkg_events)\n",
    "        \n",
    "print(\"Extracted %7d background events\" % num_bkg_events)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "855d2561-5ad1-4edf-a347-bd40de7a63c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data=None\n",
    "y_data=None\n",
    "if num_bkg_events>num_sig_events:\n",
    "    x_data = np.concatenate((x_sig_data,x_bkg_data[:num_sig_events]))\n",
    "    y_data = np.concatenate((y_sig_data,y_bkg_data[:num_sig_events]))\n",
    "else:\n",
    "    x_data = np.concatenate((x_sig_data[:num_bkg_events],x_bkg_data))\n",
    "    y_data = np.concatenate((y_sig_data[:num_bkg_events],y_bkg_data))\n",
    "\n",
    "print(y_sig_data)\n",
    "print(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5234bf2-5631-49fe-bff5-90e7d08f6475",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we read in the data as fields with a custom format, which is useful for keeping track of what's what, but \n",
    "# ML libraries wants everything as tuples of floats.  \n",
    "#x_data=[tuple(float(i) if np.isfinite(float(i)) else 0 for i in j) for j in x_data]\n",
    "x_data=[tuple(float(i) for i in j) for j in x_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fab6f31-c197-40d3-aa27-4922c7b9000b",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x_data, y_data, \n",
    "                                                    test_size=int(0.1*len(x_data)), \n",
    "                                                    random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec7e43d8-42d5-4fc9-84a1-90282b976718",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_before_scaling={}\n",
    "for b in branches:\n",
    "    x_train_before_scaling[b]=[event[branches.index(b)] for event in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85862255-2dbf-4de0-a222-b819b06e9fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,30))\n",
    "fig.tight_layout()\n",
    "for b in range(len(branches)):\n",
    "    ax=fig.add_subplot(10,5,1+b)\n",
    "    plt.subplots_adjust(hspace=0.3,wspace=0.5)\n",
    "    ax.hist(x_train_before_scaling[branches[b]])\n",
    "    ax.set_xlabel(branches[b])\n",
    "    ax.set_ylabel(\"Events/Bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadb357-23c9-4112-ab5e-ec62b9ecc96b",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20000 # number of points\n",
    "m=4 # dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dcd028-14e0-418f-8140-480910abb83e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now scale based on the training data:\n",
    "sc = StandardScaler()\n",
    "\n",
    "x_train = sc.fit_transform(x_train)\n",
    "x_test = sc.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf28b627-a654-4dc6-8fdb-0f0759e1abb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_after_scaling={}\n",
    "for b in branches:\n",
    "    x_train_after_scaling[b]=[event[branches.index(b)] for event in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a73f3a2-dd83-4245-ad0b-2e78b5fb450a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,30))\n",
    "fig.tight_layout()\n",
    "for b in range(len(branches)):\n",
    "    ax=fig.add_subplot(10,5,1+b)\n",
    "    plt.subplots_adjust(hspace=0.3,wspace=0.5)\n",
    "    ax.hist(x_train_after_scaling[branches[b]])\n",
    "    ax.set_xlabel(branches[b])\n",
    "    ax.set_ylabel(\"Events/Bin\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c88633bf-3a19-4f82-8fa3-d5a339cde874",
   "metadata": {},
   "outputs": [],
   "source": [
    "for b in branches:\n",
    "    print(x_bkg_data[b])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48315d7c-4717-427b-9238-4e838af9c5e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "fig.tight_layout()\n",
    "nbins=50\n",
    "\n",
    "for b in range(len(branches)):\n",
    "    fig = plt.figure(figsize=(20,5))\n",
    "    ax=fig.add_subplot(2,5,1+b)\n",
    "    plt.subplots_adjust(hspace=0.3,wspace=0.5)\n",
    "    plt.yscale('log')\n",
    "    ax.hist(x_sig_data[branches[b]],nbins,density=True,histtype='stepfilled',alpha=0.5,color='red')\n",
    "    ax.hist(x_bkg_data[branches[b]],nbins,density=True,histtype='stepfilled',alpha=0.5,color='blue')\n",
    "    ax.set_xlabel(f\"Feature {branches[b]}\")\n",
    "    ax.set_ylabel(\"Events/Bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c58fc41-ef24-4417-b474-788b47fe3420",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(123)\n",
    "net = torch.nn.Sequential(\n",
    "    torch.nn.Linear(len(branches), 20),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(20, 50),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(50, 20),\n",
    "    torch.nn.ReLU(),\n",
    "    torch.nn.Linear(20, 1)\n",
    ")\n",
    "torch.save(net.state_dict(), 'net.pth')\n",
    "#loss_fn = torch.nn.MSELoss()\n",
    "loss_fn = torch.nn.BCEWithLogitsLoss()\n",
    "#optimizer = torch.optim.SGD(net.parameters(), lr=0.05, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2070ee69-8d57-4f2d-beeb-da56f347f7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_tensor=torch.tensor(x_train,dtype=torch.float)\n",
    "y_train_tensor=torch.tensor(y_train,dtype=torch.float)\n",
    "y_train_tensor=y_train_tensor.unsqueeze(1)\n",
    "\n",
    "print(x_train_tensor.shape)\n",
    "\n",
    "x_test_tensor=torch.tensor(x_test,dtype=torch.float)\n",
    "y_test_tensor=torch.tensor(y_test,dtype=torch.float)\n",
    "y_test_tensor=y_test_tensor.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30204ae5-4c1d-45b9-afe2-b4d4ddc3b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import LearningCutsUtils.LearningCutsUtils\n",
    "## needed if we change LearningCutsUtils and want to avoid reloading the kernel to see the effects\n",
    "importlib.reload(LearningCutsUtils.LearningCutsUtils)\n",
    "import LearningCutsUtils.LearningCutsUtils as LCU\n",
    "from LearningCutsUtils import loss_fn\n",
    "from LearningCutsUtils import effic_loss_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f340d3dd-1687-4542-b200-d6edb42cb9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "N=20000 # number of points\n",
    "m=4 # dimensions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cddd1fa-1aaf-4c54-8f15-1d6f293aadcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gt=1.\n",
    "lt=-1.\n",
    "\n",
    "cuts_gt_lt = [lt, gt, lt, gt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce68ebd4-47d7-4a45-bf47-865bd07448bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# some hyperparameters\n",
    "activation_input_scale_factor=8.\n",
    "learning_rate=0.02\n",
    "batch_size=int(len(y_train)/20.) #\n",
    "epochs=50\n",
    "alpha=10.   # scaling factor to tune how important hitting the target signal efficiency is\n",
    "beta=10.    # scaling factor to tune how important background rejection is\n",
    "gamma=1e-3  # scaling factor for how aggressively to push the cuts to zero\n",
    "target_efficiency = 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8490c929-7aba-47ab-bb47-ac34b04b567f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = OneToOneLinear(m,activation_input_scale_factor,cuts_gt_lt)\n",
    "torch.save(net.state_dict(), 'net_learningbiases.pth')\n",
    "#optimizer = torch.optim.Adam(net.parameters(), lr=learning_rate)\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=learning_rate)\n",
    "{n: theta.shape for n, theta in net.named_parameters()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64be7286-83ac-47c4-a132-25e7460de6cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = []\n",
    "losses_test = []\n",
    "\n",
    "net.load_state_dict(torch.load('net_learningbiases.pth',weights_only=True))\n",
    "\n",
    "xy_train = torch.utils.data.TensorDataset(x_train_tensor.float(),y_train_tensor)\n",
    "loader = torch.utils.data.DataLoader(xy_train, batch_size=batch_size, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba259bf3-cbf6-4431-ade2-3cce381f6526",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "debug=False\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    net.train()\n",
    "    start_time = time.time()\n",
    "    for x_batch, y_batch in loader:\n",
    "        y_pred = net(x_batch)\n",
    "        optimizer.zero_grad()\n",
    "        loss = loss_fn(y_pred, y_batch.squeeze(1), m, net, target_efficiency, alpha, beta, gamma)\n",
    "        loss.totalloss().backward()\n",
    "        optimizer.step()\n",
    "    losses.append(loss)\n",
    "    net.eval() # configure the model for evaluation (testing)\n",
    "    y_pred = net(x_test_tensor)\n",
    "    test_loss =loss_fn(y_pred, y_test_tensor.squeeze(1), m, net, target_efficiency, alpha, beta, gamma)\n",
    "    losses_test.append(test_loss)\n",
    "    end_time=time.time()\n",
    "    elapsed_time = end_time - start_time\n",
    "    bias=net.bias[0]\n",
    "    weight=net.weight[0]\n",
    "    #weight={weight:4.1e}, bias={bias:4.1e}, \n",
    "    print(f\"Completed epoch {epoch:2d} in {elapsed_time:4.1f}s, Train loss={loss.totalloss().data:4.1e}, Test loss={test_loss.totalloss().data:4.1e}, cut={-bias/weight:4.1e}, sig_eff={100*test_loss.signaleffic:4.1f}%, bkg_eff={100*test_loss.backgreffic:6.3f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13cdc4cc-7064-4859-a109-04a83077b82c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "LearningCutsUtils.LearningCutsUtils.plotlosses(losses,losses_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "669812e1-3cdd-43e1-8e21-36ab6fcd0f72",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "net.eval() # configure the model for evaluation (testing)\n",
    "y_pred_test = net(x_test_tensor).detach().cpu()\n",
    "y_pred_train= net(x_train_tensor).detach().cpu()\n",
    "\n",
    "LearningCutsUtils.LearningCutsUtils.make_ROC_curve(y_test, y_pred_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
